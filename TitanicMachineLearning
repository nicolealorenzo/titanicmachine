# Nicole Lorenzo
# Titanic Survival Exploration

# import libraries needed
from pandas import Series, DataFrame
import pandas as pd
import numpy as np
import os
from sklearn import datasets, linear_model
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
import sklearn.metrics

# import and view the data
train_url = "http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv"
train = pd.read_csv(train_url)
test_url = "http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv"
test = pd.read_csv(test_url)
train.head()
test.head()

# passengers that survived vs passengers that passed away
print(train["Survived"].value_counts())

# as percent
print(train["Survived"].value_counts(normalize = True))

# compare male survivors vs died
print(train["Survived"][train["Sex"] == 'male'].value_counts())

# compare female survivors vs died
print(train["Survived"][train["Sex"] == 'female'].value_counts())

# normalize male "Survived" data
print(train["Survived"][train["Sex"] == 'male'].value_counts(normalize = True))

# normalize female "Survived" data
print(train["Survived"][train["Sex"] == 'female'].value_counts(normalize = True))

# create the column Child and assign to 'NaN'
train["Child"] = float('NaN')

# assign 1 to passengers under 18, 0 to those 18 or older. Print the new column.
train["Child"][train["Age"]<18] = 1
train["Child"][train["Age"]>=18] = 0
print(train["Child"])

# compare age with death and survival >18
print(train["Survived"][train["Child"] == 1].value_counts(normalize = True))

# compare age with death and survival =< 18
print(train["Survived"][train["Child"] == 0].value_counts(normalize = True))

# copy test
test_one = test

# make all general 'Surrvived' 0 
test_one["Survived"] = 0

# the 0 changes to a 1. Sex being the main factor
# set Survived to 1 if Sex equals "female" and print the `Survived` column from `test_one`
test_one["Survived"][test["Sex"] == 'female'] = 1
test_one["Survived"][test["Sex"] == 'male'] = 0
print(test_one["Survived"])

# change strings into ints so that the data can be manipulated
train["Embarked"] = train["Embarked"].fillna("S")
# Convert the Embarked classes to integer form
train["Embarked"][train["Embarked"] == "S"] = 0
train["Embarked"][train["Embarked"] == "C"] = 1
train["Embarked"][train["Embarked"] == "Q"] = 2

# view Sex and Embarked columns
print(train["Sex"])
print(train["Embarked"])

# print the train data to see the available features
print(train)

# create the target and features numpy arrays: target, features_one
target = train["Survived"].values
features_one = train[["Pclass", "Sex", "Age", "Fare"]].values
print(features_one)

# fit your first decision tree: my_tree_one
#my_tree_one = tree.DecisionTreeClassifier()
#my_tree_one = my_tree_one.fit(features_one, target)

# see what factors play the biggest role on "Survival"
print(my_tree_one.feature_importances_)
print(my_tree_one.score(features_one, target))

# any NaN values replace with median
test.Fare[152] = test.Fare.median()

# extract the features from the test set: Pclass, Sex, Age, and Fare.
test_features = test[["Pclass", "Sex", "Age", "Fare"]].values

# make prediction using the test set and print them.
my_prediction = my_tree_one.predict(test_features)
print(my_prediction)

# create a data frame with two columns: PassengerId & Survived. 
# survived contains your predictions
PassengerId =np.array(test["PassengerId"]).astype(int)
my_solution = pd.DataFrame(my_prediction, PassengerId, columns = ["Survived"])
print(my_solution)


# save solution to a csv file
my_solution.to_csv("my_solution_one.csv", index_label = ["PassengerId"])
